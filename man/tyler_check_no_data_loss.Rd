% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sanity_checks.R
\name{tyler_check_no_data_loss}
\alias{tyler_check_no_data_loss}
\title{Validate no data loss between pipeline steps}
\usage{
tyler_check_no_data_loss(
  before,
  after,
  operation = "operation",
  expected_change = 0,
  tolerance = 0
)
}
\arguments{
\item{before}{Row count before operation (or data frame)}

\item{after}{Row count after operation (or data frame)}

\item{operation}{Description of operation for error messages}

\item{expected_change}{Expected change in rows. Defaults to 0 (no change).
Use positive for operations that add rows (e.g., joins), negative for
operations that should remove rows (e.g., deduplication).}

\item{tolerance}{Maximum acceptable unexpected loss. Defaults to 0.}
}
\value{
Invisible TRUE if within expected change ± tolerance
}
\description{
Ensures row counts don't unexpectedly decrease between operations.
Use at key checkpoints in data pipelines to catch silent filtering or joins
that lose data.
}
\examples{
\dontrun{
# Expect no data loss in cleaning
before <- nrow(raw_data)
clean_data <- clean_phase_1_results(raw_data)
tyler_check_no_data_loss(before, clean_data, "Phase 1 cleaning")

# Expect deduplication to remove ~10 rows, allow ±5
before <- nrow(data)
dedup_data <- deduplicate(data)
tyler_check_no_data_loss(before, dedup_data, "Deduplication",
                        expected_change = -10, tolerance = 5)
}

}
